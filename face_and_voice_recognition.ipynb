{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1ea4db-685d-496e-aa56-d051adf2e81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.11/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: face_recognition in /opt/anaconda3/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: sounddevice in /opt/anaconda3/lib/python3.11/site-packages (0.5.2)\n",
      "Requirement already satisfied: soundfile in /opt/anaconda3/lib/python3.11/site-packages (0.13.1)\n",
      "Collecting librosa\n",
      "  Using cached librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (1.24.4)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in /opt/anaconda3/lib/python3.11/site-packages (from face_recognition) (8.1.7)\n",
      "Requirement already satisfied: dlib>=19.7 in /opt/anaconda3/lib/python3.11/site-packages (from face_recognition) (20.0.0)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.11/site-packages (from face_recognition) (10.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from sounddevice) (1.16.0)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/anaconda3/lib/python3.11/site-packages (from librosa) (0.59.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from librosa) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from librosa) (5.1.1)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Using cached soxr-0.5.0.post1-cp311-cp311-macosx_10_14_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.11/site-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/anaconda3/lib/python3.11/site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from pooch>=1.1->librosa) (23.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/anaconda3/lib/python3.11/site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.1.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.6.2)\n",
      "Using cached librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Using cached soxr-0.5.0.post1-cp311-cp311-macosx_10_14_x86_64.whl (203 kB)\n",
      "Installing collected packages: soxr, audioread, pooch, librosa\n",
      "Successfully installed audioread-3.0.1 librosa-0.11.0 pooch-1.8.2 soxr-0.5.0.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python face_recognition sounddevice soundfile librosa numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be05e0cf-b468-48e4-b403-1a652e40cc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compared with Anna: Face dist=0.30, Voice dist=106.53\n",
      "[INFO] Compared with Meghna: Face dist=0.68, Voice dist=185.49\n",
      "[INFO] Compared with Aldona: Face dist=0.67, Voice dist=96.11\n",
      "[INFO] Compared with Anna: Face dist=0.66, Voice dist=117.76\n",
      "[INFO] Compared with Meghna: Face dist=0.56, Voice dist=196.13\n",
      "[INFO] Compared with Aldona: Face dist=0.36, Voice dist=84.59\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog, messagebox\n",
    "\n",
    "DATA_FILE = \"enrolled_data.json\"\n",
    "\n",
    "def enroll_gui():\n",
    "    name = simpledialog.askstring(\"Enroll\", \"Enter your name:\")\n",
    "    if not name:\n",
    "        return\n",
    "\n",
    "    # Capture face\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    time.sleep(2)\n",
    "    messagebox.showinfo(\"Face Capture\", \"Look at the camera. Press SPACE to capture your face.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.imshow(\"Press SPACE to capture\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(' '):\n",
    "            face_file = f\"{name}_face.jpg\"\n",
    "            cv2.imwrite(face_file, frame)\n",
    "            break\n",
    "        elif key == ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            return\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Record voice\n",
    "    messagebox.showinfo(\"Voice Capture\", \"Speak into the microphone for 3 seconds...\")\n",
    "    fs = 16000\n",
    "    recording = sd.rec(int(3 * fs), samplerate=fs, channels=1)\n",
    "    sd.wait()\n",
    "    voice_file = f\"{name}_voice.wav\"\n",
    "    sf.write(voice_file, recording, fs)\n",
    "\n",
    "    # Save data\n",
    "    if os.path.exists(DATA_FILE):\n",
    "        with open(DATA_FILE, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    else:\n",
    "        data = {}\n",
    "\n",
    "    data[name] = {\"face\": face_file, \"voice\": voice_file}\n",
    "    with open(DATA_FILE, \"w\") as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "    messagebox.showinfo(\"Enroll Complete\", f\"User {name} enrolled successfully!\")\n",
    "\n",
    "def recognize_gui():\n",
    "    if not os.path.exists(DATA_FILE):\n",
    "        messagebox.showerror(\"Error\", \"No enrolled data found!\")\n",
    "        return\n",
    "\n",
    "    with open(DATA_FILE, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Capture test face\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    time.sleep(2)\n",
    "    messagebox.showinfo(\"Face Capture\", \"Look at the camera. Press SPACE to capture your face.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.imshow(\"Press SPACE to capture\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(' '):\n",
    "            test_face_file = \"test_face.jpg\"\n",
    "            cv2.imwrite(test_face_file, frame)\n",
    "            break\n",
    "        elif key == ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            return\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Record test voice\n",
    "    messagebox.showinfo(\"Voice Capture\", \"Speak into the microphone for 3 seconds...\")\n",
    "    fs = 16000\n",
    "    recording = sd.rec(int(3 * fs), samplerate=fs, channels=1)\n",
    "    sd.wait()\n",
    "    test_voice_file = \"test_voice.wav\"\n",
    "    sf.write(test_voice_file, recording, fs)\n",
    "\n",
    "    # Load test face encoding\n",
    "    test_img = face_recognition.load_image_file(test_face_file)\n",
    "    test_encs = face_recognition.face_encodings(test_img)\n",
    "    if len(test_encs) == 0:\n",
    "        messagebox.showerror(\"Error\", \"No face detected in the captured image!\")\n",
    "        return\n",
    "    test_enc = test_encs[0]\n",
    "\n",
    "    # Load test voice MFCC\n",
    "    y_test, sr_test = librosa.load(test_voice_file)\n",
    "    mfcc_test = librosa.feature.mfcc(y=y_test, sr=sr_test).mean(axis=1)\n",
    "\n",
    "    best_match = None\n",
    "    best_face_dist = float(\"inf\")\n",
    "    best_voice_dist = float(\"inf\")\n",
    "\n",
    "    for name, files in data.items():\n",
    "        enrolled_img = face_recognition.load_image_file(files[\"face\"])\n",
    "        enrolled_encs = face_recognition.face_encodings(enrolled_img)\n",
    "        if len(enrolled_encs) == 0:\n",
    "            continue\n",
    "        enrolled_enc = enrolled_encs[0]\n",
    "        face_dist = np.linalg.norm(enrolled_enc - test_enc)\n",
    "\n",
    "        y_enrolled, sr_enrolled = librosa.load(files[\"voice\"])\n",
    "        mfcc_enrolled = librosa.feature.mfcc(y=y_enrolled, sr=sr_enrolled).mean(axis=1)\n",
    "        voice_dist = np.linalg.norm(mfcc_enrolled - mfcc_test)\n",
    "\n",
    "        print(f\"[INFO] Compared with {name}: Face dist={face_dist:.2f}, Voice dist={voice_dist:.2f}\")\n",
    "\n",
    "        if face_dist < 0.6 and voice_dist < 150:\n",
    "            if face_dist + voice_dist < best_face_dist + best_voice_dist:\n",
    "                best_match = name\n",
    "                best_face_dist = face_dist\n",
    "                best_voice_dist = voice_dist\n",
    "\n",
    "    if best_match:\n",
    "        messagebox.showinfo(\"Recognition Result\",\n",
    "                            f\"Recognized as {best_match}\\nFace distance: {best_face_dist:.2f}\\nVoice distance: {best_voice_dist:.2f}\")\n",
    "    else:\n",
    "        messagebox.showinfo(\"Recognition Result\", \"No match found!\")\n",
    "\n",
    "def on_hover(event):\n",
    "    event.widget.config(bg=\"#444\", fg=\"#fff\")\n",
    "\n",
    "def on_leave(event):\n",
    "    event.widget.config(bg=\"#222\", fg=\"#ddd\")\n",
    "\n",
    "def main_gui():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Face + Voice Recognition\")\n",
    "    root.geometry(\"500x300\")\n",
    "    root.configure(bg=\"#222\")  \n",
    "\n",
    "    tk.Label(root, text=\"Face + Voice Recognition\", font=(\"Helvetica\", 20, \"bold\"), fg=\"#00BFFF\", bg=\"#222\").pack(pady=30)\n",
    "\n",
    "    btn1 = tk.Button(root, text=\"Enroll New User\", command=enroll_gui, height=2, width=20,\n",
    "                     font=(\"Helvetica\", 14), bg=\"#222\", fg=\"#ddd\", bd=0, activebackground=\"#444\", activeforeground=\"#fff\", cursor=\"hand2\")\n",
    "    btn1.pack(pady=15)\n",
    "    btn1.bind(\"<Enter>\", on_hover)\n",
    "    btn1.bind(\"<Leave>\", on_leave)\n",
    "\n",
    "    btn2 = tk.Button(root, text=\"Recognize User\", command=recognize_gui, height=2, width=20,\n",
    "                     font=(\"Helvetica\", 14), bg=\"#222\", fg=\"#ddd\", bd=0, activebackground=\"#444\", activeforeground=\"#fff\", cursor=\"hand2\")\n",
    "    btn2.pack(pady=15)\n",
    "    btn2.bind(\"<Enter>\", on_hover)\n",
    "    btn2.bind(\"<Leave>\", on_leave)\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_gui()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
